import '/cgi'
import '/json'
import '/zlib'
import '/urllib/parse/unquote'

import 'struct'


#: Parse an HTTP/1.{0,1} status line.
#:
#:   status  = method ' ' path ' ' version
#:   version = 'HTTP/1.' int10
#:
#: status :: str -> (str, str, (int, int))
#:
status = line ->
  method, _, rest  = line.partition ' '
  path, _, version = rest.partition ' '
  version.startswith 'HTTP/1.' or raise ValueError
  version = 1, int $ version !! slice 7 None
  method, path, version


#: Parse a list of HTTP headers.
#:
#:   header = first_line continuation*
#:   first_line   = name ':' value
#:   continuation = (' ' | '\t') value
#:
#: headers :: [str] -> Headers
#:
headers = lines -> struct.Headers
  where for (i, line) in enumerate lines 1 => if
    line !! 0 in ' \t' =>  # a continuation line; has already been consumed.
    not $ ':' in line  =>  # not a valid header
    otherwise =>
      line += ''.join $ takewhile (x -> x and x !! 0 in ' \t') $ drop i lines
      n, v  = line.split ':' 1
      yield (n.strip!, v.strip!)


#: Parse an `Accept` HTTP header.
#:
#:   header = entry (',' entry)*
#:   entry  = value (';' param)*
#:   param  = attr '=' float
#:   attr   = 'q' | 'mxs' | 'mxb'    # `mxs` and `mxb` are ignored.
#:
#: accept :: str -> iter (str, float)
#:
accept = data -> data =>
  for part in (data.replace ' ' '').split ',' =>
    v, *ps = part.split ';'
    q = 1
    for p in ps =>
      p.startswith 'q=' => q = except
        err => float $ p.split '=' 1 !! 1
        err :: Exception => 1
    yield (v, q)


#: Parse a list of `Cookie` headers, which are `application/x-www-urlencoded`
#: with different separators.
#:
#: cookies :: (iter str) (Optional str) -> iter (str, str)
#:
cookies = xs encoding: 'utf-8' -> for x in xs => yield from $ query x encoding ';' ' '


#: Parse an HTTP request payload, which is either `application/x-www-urlencoded'
#: or `multipart/form-data`.
#:
#: body :: bytes Headers -> Maybe (iter (str, object))
#:
body = data headers ->
  # TODO Content-Transfer-Encoding
  ctype       = headers.get 'Content-Type' ''
  ctype, args = cgi.parse_header ctype
  encoding    = args.get 'charset'  'utf-8'
  boundary    = args.get 'boundary' None
  if ctype == 'application/x-www-form-urlencoded' => query (data.decode encoding) encoding
     ctype == 'multipart/form-data' and boundary  => multipart data boundary encoding
     ctype == 'application/json'                  => jsonform $ data.decode encoding
     otherwise => None


#: Convert a valid JSON object into a `MultiDict`-able iterator.
#:
#: jsonform :: str -> iter (str, object)
#:
jsonform = xs ->
  data = json.loads xs object_hook:
    x -> struct.MultiDict $
      where for (k, v) in x.items! => if
        v :: list => for sv in v => yield (k, sv)
        otherwise => yield (k, v)
  if data :: dict => data.items
     otherwise    => None


#: Parse an application/x-www-urlencoded parameter map.
#:
#:   value = entry ('&' entry)*
#:   entry = urlencoded '=' urlencoded
#:
#: query :: str (Optional str) (Optional str) (Optional str) -> iter (str, str)
#:
query = xs encoding: 'utf-8' sep: '&' space: '+' ->
  for x in xs.split sep =>
    n, _, v = x.partition '='
    n => yield $ tuple'
      unquote (n.replace space ' ').strip! encoding
      unquote (v.replace space ' ').strip! encoding


#: Parse (nested) multipart/form-data.
#:
#:   value    = (data '\r\n')? ('--' boundary '\r\n' part '\r\n')* '--' boundary '--'
#:   boundary = <attribute of Content-Type>
#:   part     = header* '\r\n' data
#:
#: multipart :: bytes str (Optional str) -> iter (str, Either str File)
#:
multipart = data boundary encoding: 'utf-8' ->
  sep  = b'\r\n--' + boundary.encode encoding + b'\r\n'
  end  = b'\r\n--' + boundary.encode encoding + b'--\r\n'
  data = b'\r\n' + data
  # 1. There is no useful content in the preamble/epilogue for us.
  start  = data.find sep
  finish = data.rfind end
  # 2. The payload has to contain at least one boundary.
  #    It also has to end with the same boundary.
  start  >= 0 or raise StopIteration
  finish >= 0 or raise StopIteration
  data !!= slice (start + len sep) finish

  while data =>
    start  = data.find b'\r\n\r\n'
    finish = data.find sep start
    start  < 0 => raise StopIteration
    finish < 0 => finish = len data

    head    = data !! slice None start
    content = data !! slice (start + 4) finish
    data    = data !! slice (finish + len sep) None
    head    = headers $ (head.decode 'iso-8859-1').split '\r\n'

    disp, attrs = cgi.parse_header $ head.get 'Content-Disposition' ''
    name  = attrs.get 'name'     None
    fname = attrs.get 'filename' None
    xdata = body content head
    if name  is None => yield from $ xdata or list!
       xdata is None => yield $ if
         fname is None => (name, content.decode encoding)
         otherwise     => (name, struct.File fname content)
       otherwise => yield (name, struct.MultiDict xdata)


#: Read an HTTP request from an async stream.
#:
#:   data = status '\r\n' (header '\r\n')* '\r\n' body
#:   body = <either gzip | deflate | raw>
#:
#: io_request :: StreamReader -> coroutine (str, str, (int, int), Headers, bytes)
#:
io_request = reader ->
  lines = list!
  while (x = yield from reader.readline!) != b'\r\n' =>
    x.endswith b'\r\n' or raise ValueError
    x = x !! slice None -2
    lines.append $ x.decode 'iso-8859-1'
  _status  = status  $ lines.pop 0
  _headers = headers $ lines
  # NOTE `Sec-WebSocket-Key1` implies `Content-Length` of 8.
  #      This is an old standard, however; `.websocket` does not support it.
  body_length   = _headers.get 'content-length'
  body_encoding = _headers.get 'content-encoding'
  body_transfer = _headers.get 'transfer-encoding'
  _payload = if
    body_transfer == 'chunked' => yield from $ io_payload_chunked reader
    body_length                => yield from $ reader.readexactly $ int body_length
    otherwise                  => b''
  _payload = if
    body_encoding == 'deflate' => zlib.decompress _payload 15
    body_encoding == 'gzip'    => zlib.decompress _payload 31
    otherwise                  => _payload
  _status + (_headers, _payload)


#: Read chunked HTTP body from an async stream.
#:
#:   body   = (length (';' chunk-extension)? '\r\n' data '\r\n')* '0\r\n\r\n'
#:   length = <hex != 0>
#:
#: io_payload_chunked :: StreamReader -> coroutine bytes
#:
io_payload_chunked = reader ->
  data = b''
  while True =>
    line   = yield from $ reader.readline!
    length = int ((line.decode 'ascii').partition ';' !! 0) 16
    length == 0 => break!
    data  += yield from $ reader.readexactly length
    yield from (reader.readexactly 2) != b'\r\n' => raise ValueError
  yield from $ reader.readline!
  data
